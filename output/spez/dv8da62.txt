<r/announcements>: In response to recent reports about the integrity of Reddit, I’d like to share our thinking.

In the past couple of weeks, Reddit has been mentioned as one of the platforms used to promote Russian propaganda. As it’s an ongoing investigation, we have been relatively quiet on the topic publicly, which I know can be frustrating. While transparency is important, we also want to be careful to not tip our hand too much while we are investigating. We take the integrity of Reddit extremely seriously, both as the stewards of the site and as Americans.

Given the recent news, we’d like to share some of what we’ve learned:

When it comes to Russian influence on Reddit, there are three broad areas to discuss: ads, direct propaganda from Russians, indirect propaganda promoted by our users.

On the first topic, ads, there is not much to share. We don’t see a lot of ads from Russia, either before or after the 2016 election, and what we do see are mostly ads promoting spam and ICOs.  Presently, ads from Russia are blocked entirely, and all ads on Reddit are reviewed by humans. Moreover, our [ad policies](https://www.reddithelp.com/en/categories/advertising/policy-and-guidelines/reddit-advertising-policy) prohibit content that depicts intolerant or overly contentious political or cultural views.

As for direct propaganda, that is, content from accounts we suspect are of Russian origin or content linking directly to known propaganda domains, we are doing our best to identify and remove it. We have found and removed a few hundred accounts, and of course, every account we find expands our search a little more. The vast majority of suspicious accounts we have found in the past months were banned back in 2015–2016 through our enhanced efforts to prevent abuse of the site generally.

The final case, indirect propaganda, is the most complex. For example, the Twitter account @TEN\_GOP is now known to be a Russian agent. @TEN\_GOP’s Tweets were amplified by thousands of Reddit users, and sadly, from everything we can tell, these users are mostly American, and appear to be unwittingly promoting Russian propaganda. I believe the biggest risk we face as Americans is our own ability to discern reality from nonsense, and this is a burden we all bear.

I wish there was a solution as simple as banning all propaganda, but it’s not that easy. Between truth and fiction are a thousand shades of grey. It’s up to all of us—Redditors, citizens, journalists—to work through these issues. It’s somewhat ironic, but I actually believe what we’re going through right now will actually reinvigorate Americans to be more vigilant, hold ourselves to higher standards of discourse, and fight back against propaganda, whether foreign or not.

Thank you for reading. While I know it’s frustrating that we don’t share everything we know publicly, I want to reiterate that we take these matters very seriously, and we are cooperating with congressional inquiries. We are growing more sophisticated by the day, and we remain open to suggestions and feedback for how we can improve. <u/UntestedShuttle>: Edit: Apologies for highlighting another subject on an unrelated thread. Didn't intend to hijack the thread. :/

Spez, What about images of dead babies/corpses and harming animals on \/r/nomorals [**NSFL warning**] ?

18,909 subscribers and counting...

####Reddit's content policy

> ######Do not post violent content

> https://www.reddithelp.com/en/categories/rules-reporting/account-and-community-restrictions/do-not-post-violent-content

> Do not post content that encourages, **glorifies**, incites, or calls for **violence or physical harm against an individual or a group of people; likewise, do not post content that glorifies or encourages the abuse of animals**. We understand there are sometimes reasons to post violent content (e.g., educational, newsworthy, artistic, satire, documentary, etc.) so if you’re going to post something violent in nature that does not violate these terms, ensure you provide context to the viewer so the reason for posting is clear. 

---

I even had reported a bunch of threads 

https://www.reddit.com/message/messages/azbcwv

Example of the garbage [NSFL/Death warning]

https://np.reddit.com/r/nomorals/comments/81vbeh/this_is_what_evolution_looks_like/

Context: A guy is being burned death, inside a tire on a road and people surrounding him adding more fuel to it. 

He already had lots of injuries and there is some blood splatter, in all likelihood it's mob justice.

It's titled: "This is what evolution looks like"

Another example:

A dog and few puppies being hanged from their neck, its titled - "Multipurpose Wind Chime"

https://np.reddit.com/r/nomorals/comments/7t3msf/multipurpose_wind_chime/ <u/spez>: We are aware, and this community is under review.

More context: the original creator of the sub nuked it about two months ago and deleted all the content. It’s now back up and running, which is why we’re getting new reports. <u/lpisme>: "We are aware" 

OK, wonderful and I mean that. You have been "aware" of a myriad of subreddits that you rightfully nixed, from gore to near child porn. What kind of internal review process do you have for subreddits and what actually - and finally - gets stuff dropped? 

You are making a really great attempt at transparency to the extent you can with this post and it's appreciated...so can you share a little bit about what actually gets a subreddit canned or not? Because this is a constant question and it has always, at least from my understanding, been so damn grey and ambiguous. 
 <u/spez>: We don’t take banning subs lightly. Each sub is reviewed by a human—and in some cases, a team of humans—before it is banned for a content policy violation. In cases where a sub’s sole purpose is in direct violation of our policies (i.e. sharing of involuntary porn), we will ban a sub outright. But generally before banning, we attempt to work with the mods to clarify our expectations and policies regarding what content is welcome.

Communities do evolve over time, sometimes positively and sometimes negatively, so we do need to re-review communities from time to time, which is what's going on in this case. Revenue isn't a factor.